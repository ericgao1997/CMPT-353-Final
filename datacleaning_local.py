import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sys

# python3 datacleaning_local.py osm/amenities-vancouver.json.gz

SIG_TAGS = [
  # check SCHEMA.txt, generated by spark's print_schema
  # manually controlled for now
  'note',
  'notes', # honestly I just want to see what actually has notes
  'capacity',
  'amenity:cafe',
  'bar',
  'brewery',
  'club',
  'cuisine',
  'emergency', # implies healthcare, and is therefore relevant - cascades like many tags
  'fast_food',
  'ferry',
  'ferry_terminal',
  'food',
  'fuel', #discard if pedestrian
  'healthcare',
  'historic',
  'leisure',
  'memorial',
  'office',
  'public_transport',
  'ref', #what is this?
  'religion',
  'seating',
  'seats',
  'service',
  'shop',
  'social_facility',
  'sport',
  'tourism'
  
  
  #TODO wonder if its possible to consolidate these into sub-tags tbh
  #check tomorrow
  #TODO hours of operation
  #TODO merge identical columns, like "seats" "seating", "note" "notes", "food" "cuisine"
  #TODO maybe incorporate the wikidata, wikipedia (possibly yelp review) data as well???
  #will try not to bite off too much
  
]

def main(input_file):
  data = pd.read_json(input_file, lines=True)
  # json of form in SCHEMA.txt
  # https://wiki.openstreetmap.org/wiki/Tags
  # off the top of my head, I imagine tags we'd keep are something like:
  
  # bulkdata = pd.json_normalize(data)
  # bulk = pd.json_normalize(data.drop(['tags'], axis=1))
  # print(data)
  bulk = data.drop(['tags'], axis=1)
  
  tags = pd.json_normalize(data['tags'])
  
  data['tag_count'] = data.apply(lambda row: len(row['tags']), axis=1)
  # print(data['tag_count'])
  types = data.drop_duplicates(subset='amenity', keep="last")
  print(types)
  types['amenity'].to_csv("out.csv", index=False)
  
if __name__=='__main__':
  input_file = sys.argv[1]
  main(input_file)         